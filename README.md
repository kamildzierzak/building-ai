# Elements of AI - Building AI

## 1. Getting Started With AI

- [x] - Exercise 1: Listing pineapple routes
- [x] - Exercise 2: Pineapple route emissions
- [x] - Exercise 3: Reach the highest summit
- [x] - Exercise 4: Probabilities
- [x] - Exercise 5: Warm-up Temperature
- [x] - Exercise 6: Simulated Annealing

## 2. Dealing with uncertainty

- [x] - Exercise 7: Flip the coin
- [x] - Exercise 8: Fishing in the Nordics
- [x] - Exercise 9: Block or not
- [x] - Exercise 10: Naive Bayes classifier

## 3. Machine learning

- [x] - Exercise 11: Real estate price prediction
- [x] - Exercise 12: Least squares
- [x] - Exercise 13: Predictions with more data
- [x] - Exercise 14: Training data vs test data
- [x] - Exercise 15: Vector distances
- [x] - Exercise 16: Nearest neighbor
- [x] - Exercise 17: Bag of words
- [x] - Exercise 18: TF-IDF
- [x] - Exercise 19: looking out for overfitting

## 4. Neural nerworks

- [x] - Exercise 20: Logistic regression
- [x] - Exercise 21: Neural networks

## 5. Conclusion

## 6. Notes

> When talking about neural networks, we use slightly different terminology. Instead of coefficients we say weights. The non-linear part of the model, which in the case of logistic regression was the sigmoid function, is called the activation function. One such model is called a neuron. The neurons are connected to each other by letting the output of one neuron be an input of another.
>
> -- <cite>https://buildingai.elementsofai.com/Neural-Networks/from-logistic-regression-to-neural-networks</cite>
